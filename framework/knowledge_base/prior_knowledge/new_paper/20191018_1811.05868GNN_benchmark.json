{
    "paper_name": "Pitfalls of Graph Neural Network Evaluation",
    "method_name": "Graph Neural Networks (GNNs)",
    "method_summary": "The paper evaluates four prominent graph neural network architectures: Graph Convolutional Networks (GCN), Mixture Model Networks (MoNet), GraphSAGE, and Graph Attention Networks (GAT) for the task of semi-supervised node classification in graphs. The authors emphasize the importance of standardized training procedures and hyperparameter selection across all models to ensure that performance differences can be reliably attributed to the model architectures rather than to varying training setups. They analyze the impact of using the same train/validation/test splits and highlight the fragility of results based on single splits, showing that different splits can produce dramatically different rankings of the models.",
    "experiment_summary": "The authors conducted thorough empirical evaluations using both well-known citation network datasets (CORA, CiteSeer, PubMed) and four newly introduced datasets for node classification. They implemented the four GNN architectures under the same experimental conditions, using standardized training procedures and hyperparameter tuning across 100 random splits for each dataset. Results revealed that simpler GNN models could outperform more sophisticated ones when training procedures and hyperparameters were tuned equally. The authors advocate for more robust evaluation strategies in future work to properly assess the performance of GNN models."
}