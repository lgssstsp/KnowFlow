{
    "paper_name": "Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning",
    "method_name": "Adversarial Missingness (AM)",
    "method_summary": "The paper presents a novel attack strategy called Adversarial Missingness (AM) which aims to deceive causal structure learning algorithms by selectively omitting parts of the true training data. Under strict input validation conditions, the adversary's goal is to manipulate the learned causal structures (SCMs) in a desired manner. The AM model comprises an adversarial data provider who knows the complete data and selectively withholds certain features, a modeler who attempts to infer the causal structure from the partially observed data, and optionally, a data auditor who verifies the correctness of the model's output. The adversarial mechanism can be structured to achieve specific objectives, including inducing the modeler to learn an inaccurate structural causal model.",
    "experiment_summary": "The experiments validate the effectiveness of the adversarial missingness attacks using synthetic and real datasets. Various approaches such as generalized rejection sampling and a weighted EM heuristic are tested to demonstrate the manipulation of causal structure learning algorithms. The results showcase the adversary's success in misleading the learning process and highlight the distinct advantages of adversarial missingness over traditional data perturbation methods."
}