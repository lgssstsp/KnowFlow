{
    "name": "LEConv",
    "description": "The local extremum graph neural network operator from the \"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations\" paper.",
    "link": "../generated/torch_geometric.nn.conv.LEConv.html#torch_geometric.nn.conv.LEConv",
    "paper_link": "https://arxiv.org/abs/1911.07979",
    "paper_name": "\"ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\LEConv.pdf",
    "Model design and experimental setup": "{    \"GNN_Design\": {        \"agg_ops\": \"ASAP uses Local Extrema Convolution (LEConv) as the aggregation operator. LEConv captures functions of local extremas in a graph substructure by considering both global and local importance through self-loops and neighbor aggregations.\",        \"skip_connections\": \"The paper does not explicitly mention the use of skip connections in the architecture.\",        \"layer_info_fusion\": \"Information is fused across layers using LEConv which computes a fitness vector for clusters based on both the cluster's features and the differences between the features of neighboring nodes.\",        \"num_layers\": \"ASAP uses three layers of GCN, each followed by a pooling layer.\",        \"hyperparameters\": {            \"k\": \"0.5\",            \"h\": \"1\",            \"dropout\": \"0\",            \"learning_rate\": \"0.001\",            \"hidden_dimension\": \"64\",            \"l2_regularization\": \"5e-4\"        },        \"activation\": \"ReLU (used within LEConv and GCN layers)\"    },    \"Experimental_Setup\": {        \"datasets\": [\"D&D\", \"PROTEINS\", \"NCI1\", \"NCI109\", \"FRANKENSTEIN\"],        \"dataset_summary\": {            \"D&D\": \"Contains proteins as graphs with 1178 graphs, 2 classes, average 284.32 nodes, and 715.66 edges per graph.\",            \"PROTEINS\": \"Contains proteins as graphs with 1113 graphs, 2 classes, average 39.06 nodes, and 72.82 edges per graph.\",            \"NCI1\": \"Anticancer activity classification dataset with 4110 graphs, 2 classes, average 29.87 nodes, and 32.30 edges per graph.\",            \"NCI109\": \"Anticancer activity classification dataset with 4127 graphs, 2 classes, average 29.68 nodes, and 32.13 edges per graph.\",            \"FRANKENSTEIN\": \"Molecule mutagen classification dataset with 4337 graphs, 2 classes, average 16.90 nodes, and 17.88 edges per graph.\"        },        \"baseline\": [\"DiffPool\", \"TopK\", \"SAGPool\", \"Set2Set\", \"Global-Attention\", \"SortPool\"],        \"performance_comparisons\": {            \"D&D\": {                \"ASAP\": \"76.87\u00b10.70\",                \"DiffPool\": \"66.95\u00b12.41\",                \"TopK\": \"75.01\u00b10.86\",                \"SAGPool\": \"76.45\u00b10.97\",                \"Set2Set\": \"71.60\u00b10.87\",                \"Global-Attention\": \"71.38\u00b10.78\",                \"SortPool\": \"71.87\u00b10.96\"            },            \"PROTEINS\": {                \"ASAP\": \"74.19\u00b10.79\",                \"DiffPool\": \"68.20\u00b12.02\",                \"TopK\": \"71.10\u00b10.90\",                \"SAGPool\": \"71.86\u00b10.97\",                \"Set2Set\": \"72.16\u00b10.43\",                \"Global-Attention\": \"71.87\u00b10.60\",                \"SortPool\": \"73.91\u00b10.72\"            },            \"NCI1\": {                \"ASAP\": \"71.48\u00b10.42\",                \"DiffPool\": \"62.32\u00b11.90\",                \"TopK\": \"67.02\u00b12.25\",                \"SAGPool\": \"67.45\u00b11.11\",                \"Set2Set\": \"66.97\u00b10.74\",                \"Global-Attention\": \"69.00\u00b10.49\",                \"SortPool\": \"68.74\u00b11.07\"            },            \"NCI109\": {                \"ASAP\": \"70.07\u00b10.55\",                \"DiffPool\": \"61.98\u00b11.98\",                \"TopK\": \"66.12\u00b11.60\",                \"SAGPool\": \"67.86\u00b11.41\",                \"Set2Set\": \"61.04\u00b12.69\",                \"Global-Attention\": \"67.87\u00b10.40\",                \"SortPool\": \"68.59\u00b10.67\"            },            \"FRANKENSTEIN\": {                \"ASAP\": \"66.26\u00b10.47\",                \"DiffPool\": \"60.60\u00b11.62\",                \"TopK\": \"61.46\u00b10.84\",                \"SAGPool\": \"61.73\u00b10.76\",                \"Set2Set\": \"61.46\u00b10.47\",                \"Global-Attention\": \"61.31\u00b10.41\",                \"SortPool\": \"63.44\u00b10.65\"            }        }    }}",
    "Paper Summary": "The paper presents a novel graph pooling method known as ASAP (Adaptive Structure Aware Pooling), designed for efficiently learning hierarchical graph representations. The primary focus of the proposed method is on the model design aspects that enhance graph representation learning. Here\u2019s a detailed summary of the methods discussed in the paper concerning the model design.\n\n### Model Design of ASAP\n\n1. **Overview**: ASAP employs a novel self-attention mechanism combined with a modified Graph Neural Network (GNN) to capture the significance of nodes in a graph and to create a pooled graph that effectively retains structural information.\n\n2. **Adaptive Structure-Aware Pooling**:\n   - ASAP operates by initially constructing local clusters from nodes based on a fixed receptive field, effectively creating clusters from a node\u2019s h-hop neighborhood.\n   - Each node is regarded as a medoid of its cluster, and the members of the cluster are determined using a probabilistic self-attention mechanism.\n\n3. **Master2Token (M2T) Framework**:\n   - The M2T attention mechanism provides a way to summarize the cluster by generating a master representation from all nodes within the cluster.\n   - It captures the intra-cluster information more effectively than previous self-attention implementations, allowing the model to generate a more representative attention score for each node within the cluster.\n\n4. **Cluster Assignment Matrix**:\n   - A sparse cluster assignment matrix is computed using the attention scores generated by the M2T framework, which signifies the degree of membership of each node in its respective cluster.\n   - This assignment matrix is critical in maintaining the sparsity of the pooled graph, allowing the model to handle larger graphs efficiently.\n\n5. **Local Extremum Convolution (LEConv)**:\n   - LEConv is introduced as a specialized convolutional operator designed to score clusters based on their local importance. It helps in capturing local extremes, providing a fitness score for each cluster.\n   - The scores from LEConv are used to rank clusters, and a fraction of the top-scoring clusters is selected for pooling, creating a reduced graph representation.\n\n6. **Cluster Formation and Connection**:\n   -  The pooled graph is created by selecting the top clusters based on the fitness scores and recalculating edge weights to ensure meaningful connections between clusters.\n   - This is achieved through a careful consideration of the graph structure that maintains connectivity across the new pooled graph.\n\n7. **Pooled Graph Representation**:\n   - The final pooled graph retains the node features and adjacency information, allowing for improved learning in subsequent layers of the GNN.\n   - The connection strength between clusters in the pooled graph is adapted based on both the membership of constituent nodes and the edge weights between them.\n\nOverall, the architecture is designed to address the shortcomings of existing pooling methods, allowing for more effective modeling of hierarchical relationships within graphs, leading to improved performance in graph classification tasks. The use of self-attention and learnable convolutional operations in a sparse manner allows ASAP to scale effectively with larger graphs while capturing rich structural information."
}