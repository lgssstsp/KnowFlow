{
    "name": "WLConvContinuous",
    "description": "The Weisfeiler Lehman operator from the \"Wasserstein Weisfeiler-Lehman Graph Kernels\" paper.",
    "link": "../generated/torch_geometric.nn.conv.WLConvContinuous.html#torch_geometric.nn.conv.WLConvContinuous",
    "paper_link": "https://arxiv.org/abs/1906.01277",
    "paper_name": "\"Wasserstein Weisfeiler-Lehman Graph Kernels\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\WLConvContinuous.pdf",
    "Model design and experimental setup": "{    \"GNN_Design\": {        \"agg_ops\": \"The model employs a graph Wasserstein distance to measure node embedding similarities across graphs using the Wasserstein metric.\",        \"skip_connections\": \"The design does not explicitly mention using skip-connections. Instead, it aggregates node features through a Weisfeiler\u2013Lehman-inspired embedding scheme iteratively.\",        \"layer_info_fusion\": \"Information is aggregated iteratively at each Weisfeiler\u2013Lehman step, combining node labels and neighbor label information through hashing or averaging.\",        \"num_layers\": \"The number of Weisfeiler\u2013Lehman iterations (or layers) is hyperparameterized and chosen from {0,...,7}.\",        \"hyperparameters\": \"Key hyperparameters include the number of Weisfeiler\u2013Lehman iterations and the Wasserstein regularization parameter.\",        \"activation\": \"For categorical data, hashing is used as an activation-like process, while for continuous attributes, averaging is implemented.\"    },    \"Experimental_Setup\": {        \"datasets\": [            \"MUTAG\",            \"PTC-MR\",            \"NCI1\",            \"PROTEINS\",            \"D&D\",            \"ENZYMES\",            \"BZR\",            \"COX2\",            \"IMDB-BINARY\",            \"BZR-MD\",            \"COX2-MD\",            \"SYNTHETIC-NEW\",            \"SYNTHIE\"        ],        \"dataset_summary\": {            \"MUTAG\": \"Chemical compounds with categorical node labels; 188 graphs.\",            \"PTC-MR\": \"Chemical compound graph data set with 344 graphs; categorical node labels.\",            \"NCI1\": \"Compounds screened for activity against non-small cell lung cancer; 4110 graphs.\",            \"PROTEINS\": \"Graphs with protein structures having both categorical labels and continuous attributes.\",            \"D&D\": \"Macromolecular graphs with node labels; 1178 graphs.\",            \"ENZYMES\": \"Protein tertiary structures; combines node labels and continuous attributes.\",            \"BZR\": \"Chemical compounds; continuous node attributes.\",            \"COX2\": \"Graph data with continuous node attributes for COX-2 inhibitors.\",            \"IMDB-BINARY\": \"Movie collaboration data with continuous attributes derived from node degree.\",            \"BZR-MD\": \"Chemical data with continuous node attributes and edge weights.\",            \"COX2-MD\": \"Continuous node attributes and edge weights for COX2 molecular data.\",            \"SYNTHIE\": \"Synthetic graphs with continuous node attributes.\",            \"SYNTHETIC-NEW\": \"Synthetic graphs; combines generated continuous attributes.\"        },        \"baseline\": [            \"Weisfeiler\u2013Lehman kernel (WL)\",            \"Optimal Assignment kernel (WL-OA)\",            \"Hash Graph Kernel (HGK-WL, HGK-SP)\",            \"GraphHopper (GH)\",            \"Vertex Histogram\",            \"Continuous Vertex Histogram\"        ],        \"performance_comparisons\": {            \"categorical_labels\": {                \"On MUTAG\": \"WWL achieved 87.27% accuracy, better than WL (85.78%) and WL-OA (87.15%).\",                \"On D&D\": \"WWL achieved 79.69% which is higher than WL-OA at 79.15%.\"            },            \"continuous_attributes\": {                \"On ENZYMES\": \"WWL achieved 73.25% while the best baseline HGK-WL scored 66.36%.\",                \"On PROTEINS\": \"WWL scored 77.91% compared to HGK-WL's 75.93%.\"            }        }    }}",
    "Paper Summary": "### Summary of the Methods Discussed in \"Wasserstein Weisfeiler-Lehman Graph Kernels\"\n\n1. **Graph Wasserstein Distance**:\n   - The paper introduces a new distance metric between graphs called **Graph Wasserstein Distance (GWD)**, which leverages node feature distributions to provide a more nuanced comparison between graph structures. \n   - This distance is computed based on the Wasserstein distance, allowing for the capture of finer differences in the node feature distributions of graphs.\n\n2. **Graph Embedding Scheme**:\n   - The proposed method involves a **Weisfeiler\u2013Lehman-inspired embedding scheme**, designed to work for both categorical and continuous node attributes. \n   - It generates a fixed-size vector representation for each node in a graph. The scheme operates in several iterations: \n     - Initially, for each node, the initial label is assigned.\n     - At each subsequent iteration, labels are updated through a recursive scheme that aggregates labels from neighboring nodes, ultimately leading to more informative embeddings as the number of iterations increases.\n   - For continuous attributes, the scheme incorporates edge weights into the averaging process, promoting the consideration of the network structure.\n\n3. **Node Embedding Generation**:\n   - The method defines specific equations to generate **node embeddings** \\(X_h\\) for each iteration \\(h\\) in the Weisfeiler\u2013Lehman procedure. These embeddings can evolve to represent both the node's categorical label and its continuous attributes.\n   - This recursive refinement allows nodes to capture information not only from their direct neighbors but also from increasingly distant neighbors as iterations progress.\n\n4. **Computation of Wasserstein Distance**:\n   - After generating node embeddings, the pairwise Wasserstein distance between the embeddings of different graphs is computed. \n   - This calculation requires determining the ground distance between node features, which varies for categorical versus continuous attributes. \n     - For categorical features, a normalized Hamming distance is used, whereas the Euclidean distance is applied for continuous features.\n   - The Wasserstein distance is computed using an optimization approach that minimizes transport costs based on the calculated distances, effectively capturing the most efficient way to match the distributions.\n\n5. **Kernel Construction**:\n   - The Wasserstein Weisfeiler\u2013Lehman (WWL) kernel is then defined by using the computed GWD. It incorporates a parameter that weights the distance in the exponential kernel formulation, producing a measure directly usable in machine learning contexts.\n\nBy unifying concepts from optimal transport theory and graph kernels, this approach aims to improve the capacity for graph classification tasks, particularly in scenarios involving continuous node attributes, which have traditionally been challenging for existing graph kernel methods."
}