{
    "name": "LocalDegreeProfile",
    "description": "Appends the Local Degree Profile (LDP) from the \"A Simple yet Effective Baseline for Non-attribute Graph Classification\" paper (functional name: local_degree_profile).",
    "link": "../generated/torch_geometric.transforms.LocalDegreeProfile.html#torch_geometric.transforms.LocalDegreeProfile",
    "paper_link": "https://arxiv.org/abs/1811.03508",
    "paper_name": "\"A Simple yet Effective Baseline for Non-attribute Graph Classification\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\transforms\\LocalDegreeProfile.pdf",
    "Paper Summary": "The paper presents a novel approach for graph classification by introducing a simple yet effective graph representation called Local Degree Profile (LDP). The method operates on non-attributed graphs, where each graph \\( G(V, E) \\) is represented by features extracted from the nodes based on their local degree information.\n\n### Model Design Aspects:\n\n1. **Feature Extraction**:\n   - For each node \\( v \\) in the graph, the authors define a multiset of the degrees of neighboring nodes, denoted as \\( DN(v) \\).\n   - From \\( DN(v) \\), five summary statistics are computed for each node:\n     - Degree of node \\( v \\)\n     - Minimum degree in \\( DN(v) \\)\n     - Maximum degree in \\( DN(v) \\)\n     - Mean degree in \\( DN(v) \\)\n     - Standard deviation of degrees in \\( DN(v) \\)\n\n2. **Aggregation**:\n   - The node features are aggregated across the graph using either histograms or empirical distribution functions (edf), allowing for representation of degree distributions in a way that captures the local topology.\n\n3. **Input Representation**:\n   - The extracted feature vectors from multiple nodes are concatenated to form a comprehensive input feature set for a supervised learning model, specifically a Support Vector Machine (SVM).\n\n4. **Computational Complexity**:\n   - The complexity for feature extraction is linear, requiring \\( O(E) \\) time, where \\( E \\) is the number of edges in the graph. The overall processing time for feature mapping is efficient and aligned with the lower bound of reading a graph.\n\n5. **Hyperparameters**:\n   - The model has several hyperparameters that can be tuned, including:\n     - **Bin Size**: Number of bins for discretizing the degree distribution.\n     - **Normalization**: Options for normalizing either the individual graphs or the whole dataset collectively.\n     - **Representation Method**: The choice of using either histograms or empirical distributions for summarizing node features, which is shown to impact performance.\n     - **Feature Scaling**: Experimentation with linear versus logarithmic scales for degree distribution, as many real-world graphs exhibit power-law distributions.\n\n6. **Relation to Graph Neural Networks (GNN)**:\n   - The LDP approach is likened to GNN methods, where it summarises neighborhood statistics without training any parameters. The authors suggest that this method captures essential elements of GNNs through simplified aggregation and combination functions. Unlike GNNs, however, LDP does not involve end-to-end learning.\n\n7. **Connections with Graph Kernels**:\n   - The design also draws an analogy with the Weisfeiler-Lehman kernel, aiming to exploit local features while maintaining robustness against minor topological variations.\n\nThe authors conclude that despite its simplicity, LDP achieves competitive performance with existing state-of-the-art methods, which raises questions about the complexity of current methodologies and their need for simplification in future studies."
}