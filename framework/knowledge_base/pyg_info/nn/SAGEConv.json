{
    "name": "SAGEConv",
    "description": "The GraphSAGE operator from the \"Inductive Representation Learning on Large Graphs\" paper.",
    "link": "../generated/torch_geometric.nn.conv.SAGEConv.html#torch_geometric.nn.conv.SAGEConv",
    "paper_link": "https://arxiv.org/abs/1706.02216",
    "paper_name": "\"Inductive Representation Learning on Large Graphs\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\SAGEConv.pdf",
    "Paper Summary": "{  \"GNN_Design\": {    \"agg_ops\": \"Three main aggregation operators are proposed: mean, LSTM, and pooling. The mean aggregator is similar to a convolutional operator, the LSTM aggregator introduces sequential dependencies through a randomly permuted sequence of neighbors, and the pooling aggregator applies an element-wise max-pooling.\",    \"skip_connections\": \"Skip-connections are implemented by concatenating a nodeâ€™s previous layer representation with the aggregated neighborhood vector, which is particularly used except in the mean-based convolutional variant.\",    \"layer_info_fusion\": \"Information is fused across layers through concatenation and fully connected layers with non-linear activation functions applied post aggregation.\",    \"num_layers\": \"The model typically uses 2 layers for aggregation, with experiments showing K = 2 being optimal for computational efficiency.\",    \"hyperparameters\": \"Includes neighborhood sample sizes S1 = 25 and S2 = 10, hidden dimension for LSTM 256, pooling dimensions 1024 for large models, optimized using Adam optimizer.\",    \"activation\": \"Rectified linear units (ReLU) are used as the activation functions for non-linear transformations.\"  },  \"Experimental_Setup\": {    \"datasets\": \"The main datasets include citation data from Web of Science, Reddit post data, and protein-protein interaction (PPI) graphs.\",    \"dataset_summary\": \"Citation data involves classifying paper subjects in a large citation network, Reddit data predicts community membership of posts based on user interactions, and the PPI dataset classifies protein roles across different human tissue networks.\",    \"baseline\": \"Baselines used for comparison include a random classifier, a logistic regression on features, DeepWalk embeddings, and concatenation of DeepWalk with raw features.\",    \"performance_comparisons\": \"GraphSAGE outperforms baselines significantly in terms of F1 score on citation, Reddit, and PPI datasets. Pooling and LSTM-based aggregators show superior performance compared to mean and GCN-based methods.\"  }}"
}