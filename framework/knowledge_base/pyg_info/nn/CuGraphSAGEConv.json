{
    "name": "CuGraphSAGEConv",
    "description": "The GraphSAGE operator from the \"Inductive Representation Learning on Large Graphs\" paper.",
    "link": "../generated/torch_geometric.nn.conv.CuGraphSAGEConv.html#torch_geometric.nn.conv.CuGraphSAGEConv",
    "paper_link": "https://arxiv.org/abs/1706.02216",
    "paper_name": "\"Inductive Representation Learning on Large Graphs\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\CuGraphSAGEConv.pdf",
    "Paper Summary": "{    \"GNN_Design\": {        \"agg_ops\": \"The paper introduces a general inductive framework called GraphSAGE (SAmple and aggreGatE) which uses different aggregation operators: Mean aggregator (element-wise mean of neighbors' vectors), LSTM aggregator (applies LSTM to a random permutation of the node's neighbors), and Pooling aggregator (neighbors' vectors fed through a fully-connected neural network followed by a max-pooling operation).\",        \"skip_connections\": \"GraphSAGE employs skip connections by concatenating the nodeâ€™s current representation with the aggregated neighborhood vector, enabling information from different search depths to be combined. However, the convolutional variant does not perform this concatenation.\",        \"layer_info_fusion\": \"Information is fused across layers by applying a learned weight matrix and activation function to both the current node representation and the aggregated neighborhood vector, followed by normalization.\",        \"num_layers\": \"The framework typically uses 2 layers, but performance gains diminish beyond 2 layers.\",        \"hyperparameters\": \"Important hyperparameters include the number of layers (depth K), the neighborhood sample sizes (S1, S2), learning rates for different methods, the dimension of node representations, pooling dimensions, and the number of negative samples (Q) for the unsupervised loss.\",        \"activation\": \"GraphSAGE uses rectified linear units (ReLUs) as the activation function.\"    },    \"Experimental_Setup\": {        \"datasets\": \"Web of Science citation data, Reddit discussion forum data, and protein-protein interaction (PPI) graphs.\",        \"dataset_summary\": {            \"citation_data\": \"Graph dataset from the Thomson Reuters Web of Science (2000-2005), predicting categories of scientific papers. It includes 302,424 nodes with an average degree of 9.15.\",            \"reddit_data\": \"Reddit post dataset (September 2014), predicting the community a post belongs to via a post-to-post graph. It contains 232,965 posts with an average degree of 492.\",            \"ppi_data\": \"Protein-protein interaction graphs from human tissue data, predicting protein functions. The average graph contains 2373 nodes with an average degree of 28.8.\"        },        \"baseline\": \"Baselines include a random classifier, a logistic regression feature-based classifier, the DeepWalk algorithm, and a concatenation of raw features and DeepWalk embeddings.\",        \"performance_comparisons\": {            \"citation_data\": {                \"unsupervised_f1\": {                    \"random\": 0.206,                    \"features_only\": 0.575,                    \"deepwalk\": 0.565,                    \"deepwalk+features\": 0.701,                    \"graphsage_gcn\": 0.742,                    \"graphsage_mean\": 0.778,                    \"graphsage_lstm\": 0.788,                    \"graphsage_pool\": 0.798                },                \"supervised_f1\": {                    \"random\": 0.206,                    \"features_only\": 0.575,                    \"graphsage_gcn\": 0.772,                    \"graphsage_mean\": 0.820,                    \"graphsage_lstm\": 0.832,                    \"graphsage_pool\": 0.839                }            },            \"reddit_data\": {                \"unsupervised_f1\": {                    \"random\": 0.043,                    \"features_only\": 0.585,                    \"deepwalk\": 0.324,                    \"deepwalk+features\": 0.691,                    \"graphsage_gcn\": 0.908,                    \"graphsage_mean\": 0.897,                    \"graphsage_lstm\": 0.907,                    \"graphsage_pool\": 0.892                },                \"supervised_f1\": {                    \"random\": 0.042,                    \"features_only\": 0.585,                    \"graphsage_gcn\": 0.930,                    \"graphsage_mean\": 0.950,                    \"graphsage_lstm\": 0.954,                    \"graphsage_pool\": 0.948                }            },            \"ppi_data\": {                \"unsupervised_f1\": {                    \"random\": 0.396,                    \"features_only\": 0.422,                    \"graphsage_gcn\": 0.465,                    \"graphsage_mean\": 0.486,                    \"graphsage_lstm\": 0.482,                    \"graphsage_pool\": 0.502                },                \"supervised_f1\": {                    \"random\": 0.396,                    \"features_only\": 0.422,                    \"graphsage_gcn\": 0.500,                    \"graphsage_mean\": 0.598,                    \"graphsage_lstm\": 0.612,                    \"graphsage_pool\": 0.600                }            }        }    }}"
}