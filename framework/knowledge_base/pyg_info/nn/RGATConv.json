{
    "name": "RGATConv",
    "description": "The relational graph attentional operator from the \"Relational Graph Attention Networks\" paper.",
    "link": "../generated/torch_geometric.nn.conv.RGATConv.html#torch_geometric.nn.conv.RGATConv",
    "paper_link": "https://arxiv.org/abs/1904.05811",
    "paper_name": "\"Relational Graph Attention Networks\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\RGATConv.pdf",
    "Paper Summary": "{    \"GNN_Design\": {        \"agg_ops\": \"Two specific attention mechanisms: Within-Relation Graph Attention (WIRGAT) and Across-Relation Graph Attention (ARGAT), with either additive or multiplicative logit mechanisms.\",        \"skip_connections\": \"No explicit mention of skip connections in the described architecture.\",        \"layer_info_fusion\": \"The attention mechanisms use intermediate representations and attention coefficients for each relation type, with a softmax operation applied to produce attention weights for aggregating neighboring node information.\",        \"num_layers\": \"Two-layer architecture is extensively discussed and evaluated.\",        \"hyperparameters\": \"Hyperparameters for transductive tasks include the number of graph kernel units, number of attention heads, dropout rates, basis size for weight and attention matrices, L2 regularization coefficients, learning rate, bias usage, and batch normalization. Detailed ranges are provided in appendices.\",        \"activation\": \"ReLU activation is used after the RGAT concat layer, and node-wise softmax is applied on the final layer. For the graph gather operation, a tanh activation is employed.\"    },    \"Experimental_Setup\": {        \"datasets\": [\"AIFB\", \"MUTAG\", \"Tox21\"],        \"dataset_summary\": {            \"AIFB\": \"Transductive node classification task with 8,285 nodes, 29,043 edges, 45 relations, and 176 labeled nodes divided into 4 classes.\",            \"MUTAG\": \"Transductive node classification task with 23,644 nodes, 74,227 edges, 23 relations, and 340 labeled nodes divided into 2 classes.\",            \"Tox21\": \"Inductive graph classification task containing 145,459 nodes across 8,014 graphs, with 151,095 edges and 96,168 labeled samples over 12 multi-label classes.\"        },        \"baseline\": [            \"RGCN, FEAT, WL, RDF2Vec for transductive tasks\",            \"Deep multitask networks, deep bypass multitask networks, Weave, and RGCN for inductive tasks\"        ],        \"performance_comparisons\": \"For AIFB, the best performing model is additive WIRGAT. RGCN outperforms RGAT on MUTAG. On Tox21, multiplicative ARGAT and WIRGAT marginally outperform RGCN. Performance metrics are detailed with mean and standard deviations provided for accuracy and ROC-AUC across various splits and seeds.\"    }}"
}