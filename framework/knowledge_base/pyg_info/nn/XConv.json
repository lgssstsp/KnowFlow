{
    "name": "XConv",
    "description": "The convolutional operator on \\(\\mathcal{X}\\)-transformed points from the \"PointCNN: Convolution On X-Transformed Points\" paper.",
    "link": "../generated/torch_geometric.nn.conv.XConv.html#torch_geometric.nn.conv.XConv",
    "paper_link": "https://arxiv.org/abs/1801.07791",
    "paper_name": "\"PointCNN: Convolution On X-Transformed Points\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\XConv.pdf",
    "Paper Summary": "{    \"GNN_Design\": {        \"agg_ops\": \"The X-Conv operator utilizes a combination of element-wise product and sum operations, followed by matrix multiplication with transform matrices learned through MLPs.\",        \"skip_connections\": \"Skip connections are implemented in the form of dilation and ensuring that deeper layers have larger receptive fields to capture more comprehensive features.\",        \"layer_info_fusion\": \"Information from different layers is fused using combined feature maps where features from neighborhood points are transformed through the X-Conv mechanism; local coordinates of points combined with learned weights contribute to the final output.\",        \"num_layers\": \"Various PointCNN architectures are proposed, typically comprising 4 to 6 X-Conv layers, with some configurations having specific setups based on tasks (e.g., segmentation requiring more layers).\",        \"hyperparameters\": \"Using MLP(·) with configurations such as FC(3*C, K*K)→ELU→BN repeated with required dimensions for different layers.\",        \"activation\": \"Exponential Linear Units (ELUs) followed by Batch Normalization (BN) are used after fully connected (FC) layers in the MLP components.\"    },    \"Experimental_Setup\": {        \"datasets\": [            \"ModelNet40\",            \"ScanNet\",            \"ShapeNetParts\",            \"S3DIS\",            \"TU-Berlin\",            \"QuickDraw\",            \"MNIST\",            \"CIFAR10\"        ],        \"dataset_summary\": {            \"ModelNet40\": \"Consists of 12,311 3D mesh models from 40 categories, with training and testing splits. Evaluated in 'Pre-aligned' and 'Unaligned' settings.\",            \"ScanNet\": \"Comprising of 1513 3D scanned indoor scenes. Evaluated for semantic segmentation and object classification.\",            \"ShapeNetParts\": \"Contains 16,880 models across 16 categories, each labeled with parts.\",            \"S3DIS\": \"3D scans from six areas, including 271 rooms, labeled with 13 semantic categories.\",            \"TU-Berlin\": \"2D sketch dataset with 250 categories, each having 80 sketches used for training and testing.\",            \"QuickDraw\": \"Large sketch dataset with 345 categories and about 70,000 training and 2,500 testing samples per category.\",            \"MNIST\": \"Converted to point cloud format for evaluation; digits are represented as binary images.\",            \"CIFAR10\": \"Also converted into point cloud representation for evaluation; data originally 32x32 RGB images.\"        },        \"baseline\": [            \"Flex-Convolution\",            \"KCNet\",            \"Kd-Net\",            \"SO-Net\",            \"3DmFV-Net\",            \"PCNN\",            \"PointNet\",            \"PointNet++\",            \"SpecGCN\",            \"SpiderCNN\",            \"DGCNN\"        ],        \"performance_comparisons\": {            \"ModelNet40\": {                \"Pre-aligned\": {                    \"mPA\": 88.8,                    \"mOA\": 92.5                },                \"Unaligned\": {                    \"mPA\": 88.1,                    \"mOA\": 92.2                }            },            \"ScanNet\": {                \"mOA\": 79.7,                \"mPA\": 55.7            },            \"ShapeNetParts\": {                \"pIoU\": 86.14,                \"mpIoU\": 84.6            },            \"S3DIS\": {                \"mIoU\": 65.39,                \"mAcc\": 75.61,                \"OA\": 88.14            },            \"TU-Berlin\": {                \"Accuracy\": 70.57            },            \"QuickDraw\": {                \"Accuracy\": 59.13            },            \"MNIST\": {                \"Accuracy\": 99.54            },            \"CIFAR10\": {                \"Accuracy\": 80.22            }        }    }}"
}