{
    "name": "FiLMConv",
    "description": "The FiLM graph convolutional operator from the \"GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation\" paper.",
    "link": "../generated/torch_geometric.nn.conv.FiLMConv.html#torch_geometric.nn.conv.FiLMConv",
    "paper_link": "https://arxiv.org/abs/1906.12192",
    "paper_name": "\"GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\FiLMConv.pdf",
    "Paper Summary": "{    \"GNN_Design\": {        \"agg_ops\": \"Message passing based on target node representation with affine transformation using FiLM.\",        \"skip_connections\": \"Residual connections after every second layer.\",        \"layer_info_fusion\": \"Dynamic affine transformations allowing fine-grained gating based on edge types.\",        \"num_layers\": \"Eight layers for GNN-FiLM, varying between 3 and 10 for others.\",        \"hyperparameters\": \"Hidden size of 320, dropout keep probability of 0.9, layer normalization applied.\",        \"activation\": \"Non-linearity applied before aggregation, either tanh or another activation function.\"    },    \"Experimental_Setup\": {        \"datasets\": \"PPI, QM9, VarMisuse\",        \"dataset_summary\": {            \"PPI\": \"24 graphs with around 2500 nodes each for protein-protein interaction, node classification task.\",            \"QM9\": \"~130k molecular graphs with various quantum properties, graph regression tasks.\",            \"VarMisuse\": \"~235k program graphs, variable misuse detection, graph classification.\"        },        \"baseline\": \"GGNN, R-GCN, R-GAT, R-GIN, GNN-MLP\",        \"performance_comparisons\": {            \"PPI\": \"GNN-FiLM achieved an average Micro-F1 score of 0.992 outperforming baselines.\",            \"QM9\": \"GNN-FiLM showed competitive results across multiple properties, slightly outperforming others.\",            \"VarMisuse\": \"GNN-FiLM showed accuracy of 87.0% on SEENPROJTEST, 81.3% on UNSEENPROJTEST.\"        }    }}"
}