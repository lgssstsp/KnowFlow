{
    "name": "ARMAConv",
    "description": "The ARMA graph convolutional operator from the \"Graph Neural Networks with Convolutional ARMA Filters\" paper.",
    "link": "../generated/torch_geometric.nn.conv.ARMAConv.html#torch_geometric.nn.conv.ARMAConv",
    "paper_link": "https://arxiv.org/abs/1901.01343",
    "paper_name": "\"Graph Neural Networks with Convolutional ARMA Filters\"",
    "Local Paper PDF Path": "knowledge_base\\pyg_info\\nn\\ARMAConv.pdf",
    "Paper Summary": "{    \"GNN_Design\": {        \"agg_ops\": \"ARMA filters are based on a non-linear and trainable frequency response in the spectral domain.\",        \"skip_connections\": \"The ARMA layer includes skip connections that are defined by the combination of initial node features with representations learned through the GCS layer.\",        \"layer_info_fusion\": \"Fusing is achieved by recursive stacks of GCNs with filter coefficients learned end-to-end.\",        \"num_layers\": \"K parallel stacks of GCS layers with depth T.\",        \"hyperparameters\": \"Number of stacks (K) and depth (T), with options for dropout and L2 regularization.\",        \"activation\": \"ReLU, sigmoid, or hyperbolic tangent.\"    },    \"Experimental_Setup\": {        \"datasets\": [            \"Cora\",            \"Citeseer\",            \"Pubmed\",            \"PPI\",            \"MNIST\",            \"20news\",            \"Enzymes\",            \"Proteins\",            \"D&D\",            \"MUTAG\",            \"Bench-hard\",            \"QM9\"        ],        \"dataset_summary\": {            \"Cora\": \"2708 nodes, 5429 edges, 1433 features, 7 classes.\",            \"Citeseer\": \"3327 nodes, 9228 edges, 3703 features, 6 classes.\",            \"Pubmed\": \"19717 nodes, 88651 edges, 500 features, 3 classes.\",            \"PPI\": \"56944 nodes, 818716 edges, 50 features, 121 classes.\",            \"MNIST\": \"Graph with 784 nodes and edges based on pixel distance.\",            \"20news\": \"10k node graph with edges derived from word embeddings.\",            \"Enzymes\": \"600 graphs, node attributes, edge attributes, 6 classes.\",            \"Proteins\": \"1113 graphs, node attributes, edge attributes, 2 classes.\",            \"D&D\": \"1178 graphs, node attributes, edge attributes, 2 classes.\",            \"MUTAG\": \"188 graphs, node labels, 2 classes.\",            \"Bench-hard\": \"1800 graphs, node labels, 3 classes.\",            \"QM9\": \"133,885 molecular graphs with continuous targets.\"        },        \"baseline\": \"GCN, Chebyshev, CayleyNet, GAT, GraphSAGE, GIN.\",        \"performance_comparisons\": {            \"Cora\": \"ARMA 83.4%, best among models with strong regularization needs.\",            \"Citeseer\": \"ARMA 72.5%, improved on complex architectures.\",            \"Pubmed\": \"ARMA 78.9%, competitive with other methods.\",            \"PPI\": \"ARMA 90.5%, outperforming all models significantly.\",            \"MNIST\": \"ARMA 99.20%, superior performance.\",            \"20news\": \"ARMA 70.02%, better than other layers.\",            \"Graph datasets\": \"ARMA shows higher or comparable accuracy in graph classification tasks.\",            \"QM9\": \"ARMA outperforms GCN, Chebyshev, and CayleyNet across multiple regression targets\"        }    }}"
}